# 一：全连接层  
## 1.概念的理解  
全连接层的每一个结点都与上一层的所有结点相连，用来把前边提取到的特征综合起来。  
由于其全相连的特性，一般全连接层的参数也是最多的。  
当前面的卷积层和池化层将文件的整体分割成不同的区域后，全连接层将分散的数据重新整合成为一个新的整体  
### 本质上是一个“分类器”的作用。  
如果说卷积层、池化层和激活函数层等操作是将原始数据映射到隐层特征空间的话，全连接层则起到将学到的“分布式特征表示”映射到样本标记空间的作用。  
在实际使用中，全连接层可由卷积操作实现：对前层是全连接的全连接层可以转化为卷积核为1x1的卷积  
而前层是卷积层的全连接层可以转化为卷积核为hxw的全局卷积，h和w分别为前层卷积结果的高和宽。
## 2.参数的理解  
in_features - 每个输入样本的大小  
out_features - 每个输出样本的大小  
bias - 若设置为False，这层不会学习偏置。默认值：True  
## 3.代码  
``` 
import torch  
m = torch.nn.Linear(20, 30)
input = torch.utograd.Variable(torch.randn(128, 20))
output = m(input)
print(output.size())
```  
结果：  
```  
torch.Size([128, 30])  
```  

## 1.全连接神经网络  
仅由全连接层组成的前馈神经网络。通俗来讲，是所有数据都会影响卷积出的数据，卷积出的数据是所有数据的整体，并不是局部。  
使用函数  torch.nn.Sequential.  
所有，所有神经元层必须是全连接层  
*每一个数据都会对最终的结果产生影响*  
# 二：数据处理  
## 1.数据类型的选择  
32位浮点型张量 ____ 回归数据___   
64位有符号整形数据    分类数据（离散数据）  
## 2.加载器  
出现原因：在处理大规模数据的时候，统一放入内存在进行分析时间太久，会导致程序运行中断，大大降低运行速度  
所以出现**在自动批处理支持下并行化数据加载过程的解决方案** ——加载器  
### 加载器的参数说明  
#### （1）dataset (Dataset) – 加载数据的数据集。  
一共有两类 
##### （1）映射样式的数据集：  
通过__get_item__()方法实现检索的（随机读取）
##### （2）可 __iter__() 样式的数据集  
数据集按流序列检索数据 也就是按照顺序进行读取  
#### （2）batch_size (int, optional)  
每个batch加载多少个样本(默认: 1)  
#### （3）shuffle (bool, optional)  
设置为True时会在每个epoch重新打乱数据(默认: False).  
#### （4）sampler (Sampler, optiona）  
定义从数据集中提取样本的策略。如果指定，则忽略shuffle参数。  
采样器定义了检索样本的策略-顺序，随机或任何其他方式。 使用采样器时，应将随机播放设置为false。 
#### （5）num_workers (int, optional)  
用多少个子进程加载数据。0表示数据将在主进程中加载(默认: 0)  
#### （6）Batch_Sampler (bool, optional)  
是否批处理级别工作  
#### （7）collate_fn (callable, optional)  
将样本整理为批次。 在Torch中可以自定义排序规则。
#### （8）pin_memory (bool, optional)  
固定（页面锁定）的内存位置供GPU使用，以加快数据访问速度。 设置为True时，此选项使数据加载器可以将张量复制到CUDA固定的内存中。 
#### （9）  drop_last (bool, optional)   
如果数据集大小不能被batch size整除，则设置为True后可删除最后一个不完整的batch。  

如果设为False并且数据集的大小不能被batch size整除，则最后一个batch  将更小。(默认: False)  
*最后总结加载器的使用流程*  
1.读取数据到数据集，数据集使用特定的方式进行读取    
2.把数据集按照batch_size的数量加载样本（）  
3.Batch_Sampler来判断是否同时批处理数据 （是则进入collate-fn整理批次）   
4.加载数据时是否进行分割等操作还是直接进入主程序（num_workers）  
5.第一批的数据准备完毕，pin_memory判断是否将张量复制到CUDA内存中进行加速  
**如果选择批处理，可能出现数据集大小不能被batch-size整除的问题**，如果出现此情况  
进行第六步 drop_last选择是否删除最后一个不完整的batch


